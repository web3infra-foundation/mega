use super::{graph::Graph, DagError};
use crate::{
    task::{ExecState, Input, Task},
    utils::EnvVar,
    Action, Parser,
    Output,
};
use log::{debug, error};
use std::{
    collections::HashMap,
    panic::{self, AssertUnwindSafe},
    sync::{
        atomic::{AtomicBool, Ordering},
        Arc,
    },
};
use tokio::task::JoinHandle;

/// [`Dag`] is dagrs's main body.
///
/// [`Dag`] embodies the scheduling logic of tasks written by users or tasks in a given configuration file.
/// A Dag contains multiple tasks. This task can be added to a Dag as long as it implements
/// the [`Task`] trait, and the user needs to define specific execution logic for the task, that is,
/// implement the [`Action`] trait and override the `run` method.
///
/// The execution process of Dag is roughly as follows:
/// - The user gives a list of tasks `tasks`. These tasks can be parsed from configuration files, or provided
///   by user programming implementations.
/// - Internally generate `Graph` based on task dependencies, and generate execution sequences based on `rely_graph`.
/// - The task is scheduled to start executing asynchronously.
/// - The task will wait to get the result `execute_states` generated by the execution of the predecessor task.
/// - If the result of the predecessor task can be obtained, check the continuation status `can_continue`, if it
///   is true, continue to execute the defined logic, if it is false, trigger `handle_error`, and cancel the
///   execution of the subsequent task.
/// - After all tasks are executed, set the continuation status to false, which means that the tasks of the dag
///   cannot be scheduled for execution again.
///
///  # Example
/// ```rust
/// use dagrs::{Dag, DefaultTask, Output,Input,EnvVar,Action};
/// use std::sync::Arc;
/// env_logger::init();
/// let task=DefaultTask::with_closure("Simple Task",|_input,_env|{
///     Output::new(1)
/// });
/// let mut dag=Dag::with_tasks(vec![task]);
/// assert!(dag.start().is_ok())
///
/// ```
#[derive(Debug)]
pub struct Dag {
    /// Store all tasks' infos.
    ///
    /// Arc but no mutex, because only one thread will change [`TaskWrapper`]at a time.
    /// And no modification to [`TaskWrapper`] happens during the execution of it.
    pub tasks: HashMap<usize, Box<dyn Task>>,
    /// Store dependency relations.
    rely_graph: Graph,
    /// Store a task's running result.Execution results will be read and written asynchronously by several threads.
    execute_states: HashMap<usize, Arc<ExecState>>,
    /// Global environment variables for this Dag job. It should be set before the Dag job runs.
    env: Arc<EnvVar>,
    /// Mark whether the Dag task can continue to execute.
    /// When an error occurs during the execution of any task, this flag will be set to false, and
    /// subsequent tasks will be canceled.
    /// when all tasks in the dag are executed, the flag will also be set to false, indicating that
    /// the task cannot be run repeatedly.
    can_continue: Arc<AtomicBool>,
    /// A flag that indicates whether the task should continue to execute as much as possible.
    keep_going: bool,
    /// When `keep_going` is true, and an error occurs during the execution of a task, this flag will be set to true.
    keep_going_errored: Arc<AtomicBool>,
    /// The execution sequence of tasks.
    exe_sequence: Vec<usize>,
}

impl Dag {
    /// Create a dag. This function is not open to the public. There are three ways to create a new
    /// dag, corresponding to three functions: `with_tasks`, `with_yaml`, `with_config_file_and_parser`.
    fn new() -> Dag {
        Dag {
            tasks: HashMap::new(),
            rely_graph: Graph::new(),
            execute_states: HashMap::new(),
            env: Arc::new(EnvVar::new()),
            can_continue: Arc::new(AtomicBool::new(true)),
            exe_sequence: Vec::new(),
            keep_going: false,
            keep_going_errored: Arc::new(AtomicBool::new(false)),
        }
    }

    /// Reset the graph state but keep the tasks.
    pub fn reset(&mut self) {
        self.rely_graph = Graph::new();
        self.execute_states = HashMap::new();
        self.env = Arc::new(EnvVar::new());
        self.can_continue = Arc::new(AtomicBool::new(true));
        self.exe_sequence = Vec::new();
        self.keep_going = false;
        self.keep_going_errored = Arc::new(AtomicBool::new(false));
    }

    /// Create a dag by adding a series of tasks.
    pub fn with_tasks(tasks: Vec<impl Task + 'static>) -> Dag {
        let mut dag = Dag::new();

        dag.tasks = tasks
            .into_iter()
            .map(|task| (task.id(), Box::new(task) as Box<dyn Task>))
            .collect();

        dag
    }

    /// Create a dag by adding a series of tasks that implement the [`Task`] trait.
    pub fn with_tasks_dyn(tasks: Vec<Box<dyn Task>>) -> Dag {
        let mut dag = Dag::new();

        dag.tasks = tasks.into_iter().map(|task| (task.id(), task)).collect();

        dag
    }

    /// Given a yaml configuration file parsing task to generate a dag.
    #[cfg(feature = "yaml")]
    pub fn with_yaml(
        file: &str,
        specific_actions: HashMap<String, Action>,
    ) -> Result<Dag, DagError> {
        use crate::YamlParser;
        let parser = Box::new(YamlParser);
        Dag::read_tasks(file, parser, specific_actions)
    }

    /// Given a yaml configuration file parsing task to generate a dag.
    #[cfg(feature = "yaml")]
    pub fn with_yaml_str(
        content: &str,
        specific_actions: HashMap<String, Action>,
    ) -> Result<Dag, DagError> {
        use crate::YamlParser;
        let parser = Box::new(YamlParser);
        Dag::read_tasks_from_str(content, parser, specific_actions)
    }

    /// Generates a dag with the user given path to a custom parser and task config file.
    pub fn with_config_file_and_parser(
        file: &str,
        parser: Box<dyn Parser>,
        specific_actions: HashMap<String, Action>,
    ) -> Result<Dag, DagError> {
        Dag::read_tasks(file, parser, specific_actions)
    }

    /// Generates a dag with the user given path to a custom parser and task config file.
    pub fn with_config_str_and_parser(
        content: &str,
        parser: Box<dyn Parser>,
        specific_actions: HashMap<String, Action>,
    ) -> Result<Dag, DagError> {
        Dag::read_tasks_from_str(content, parser, specific_actions)
    }

    /// Set the flag that indicates whether the task should continue to execute as much as possible.
    /// This means that even if an error occurs during the execution of a task, the subsequent independent tasks
    /// will continue to execute unless a dependency error occurs.
    pub fn keep_going(mut self) -> Dag {
        self.keep_going = true;
        self
    }

    /// Parse the content of the configuration file into a series of tasks and generate a dag.

    fn read_tasks(
        file: &str,
        parser: Box<dyn Parser>,
        specific_actions: HashMap<String, Action>,
    ) -> Result<Dag, DagError> {
        let tasks = parser.parse_tasks(file, specific_actions)?;

        let mut dag = Dag::new();
        dag.tasks = tasks.into_iter().map(|task| (task.id(), task)).collect();

        Ok(dag)
    }

    /// Parse the content of the configuration file into a series of tasks and generate a dag.

    fn read_tasks_from_str(
        content: &str,
        parser: Box<dyn Parser>,
        specific_actions: HashMap<String, Action>,
    ) -> Result<Dag, DagError> {
        let tasks = parser.parse_tasks_from_str(content, specific_actions)?;

        let mut dag = Dag::new();
        dag.tasks = tasks.into_iter().map(|task| (task.id(), task)).collect();

        Ok(dag)
    }

    /// create rely map between tasks.
    ///
    /// This operation will initialize `dagrs.rely_graph` if no error occurs.
    fn create_graph(&mut self) -> Result<(), DagError> {
        let size = self.tasks.len();
        self.rely_graph.set_graph_size(size);

        // Add Node (create id - index mapping)
        self.tasks
            .iter()
            .for_each(|(&n, _)| self.rely_graph.add_node(n));

        // Form Graph
        for (&id, task) in self.tasks.iter() {
            let index = self.rely_graph.find_index_by_id(&id).unwrap();

            for rely_task_id in task.precursors() {
                // Rely task existence check
                let rely_index = self
                    .rely_graph
                    .find_index_by_id(rely_task_id)
                    .ok_or(DagError::RelyTaskIllegal(task.name().to_string()))?;

                self.rely_graph.add_edge(rely_index, index);
            }
        }

        Ok(())
    }

    /// Initialize dags. The initialization process completes three actions:
    /// - Initialize the status of each task execution result.
    /// - Create a graph from task dependencies.
    /// - Generate task heart sequence according to topological sorting of graph.
    pub(crate) fn init(&mut self) -> Result<(), DagError> {
        self.execute_states.reserve(self.tasks.len());
        self.tasks.values().for_each(|task| {
            self.execute_states
                .insert(task.id(), Arc::new(ExecState::new()));
        });

        self.create_graph()?;

        match self.rely_graph.topo_sort() {
            Some(seq) => {
                if seq.is_empty() {
                    return Err(DagError::EmptyJob);
                }
                let exe_seq: Vec<usize> = seq
                    .into_iter()
                    .map(|index| self.rely_graph.find_id_by_index(index).unwrap())
                    .collect();
                self.exe_sequence = exe_seq;
                Ok(())
            }
            None => Err(DagError::LoopGraph),
        }
    }

    /// This function is used for the execution of a single dag.
    pub fn start(&mut self) -> Result<(), DagError> {
        // If the current continuable state is false, the task will start failing.
        if self.can_continue.load(Ordering::Acquire) {
            self.init().map_or_else(Err, |_| {
                tokio::runtime::Runtime::new()
                    .unwrap()
                    .block_on(async { self.run().await })
            })
        } else {
            // TODO: Change this error
            Err(DagError::EmptyJob)
        }
    }

    /// Execute tasks sequentially according to the execution sequence given by
    /// topological sorting, and cancel the execution of subsequent tasks if an
    /// error is encountered during task execution.
    pub(crate) async fn run(&self) -> Result<(), DagError> {
        debug!("[Start]{} -> [End]", {
            self.exe_sequence
                .iter()
                .map(|id| self.tasks[id].name())
                .collect::<Vec<&str>>()
                .join(" -> ")
        });

        let handles = self
            .exe_sequence
            .iter()
            .map(|id| (*id, self.execute_task(self.tasks[id].as_ref())))
            .collect::<Vec<_>>();

        // Wait for the status of each task to execute. If there is an error in the execution of a task,
        // the engine will fail to execute and give up executing tasks that have not yet been executed.
        for (tid, handle) in handles {
            match handle.await {
                Ok(succeed) => {
                    if succeed.is_err() {
                        self.handle_error(tid);
                    }
                }
                Err(err) => {
                    error!("Task execution encountered an unexpected error! {}", err);
                    self.handle_error(tid);
                }
            }
        }
        if self.keep_going {
            // when keep_going is true, the task will continue to execute as much as possible.
            // So, the success is evaluated by keep_going_errored.
            if !self.keep_going_errored.load(Ordering::Relaxed) {
                Ok(())
            } else {
                Err(DagError::EmptyJob)
            }
        } else if self
            .can_continue
            .compare_exchange(true, false, Ordering::Relaxed, Ordering::Relaxed)
            .is_ok()
        {
            Ok(())
        } else {
            Err(DagError::EmptyJob)
        }
    }

    /// Execute a given task asynchronously.
    fn execute_task(&self, task: &dyn Task) -> JoinHandle<Result<(), DagError>> {
        let env = self.env.clone();
        let task_id = task.id();
        let task_name = task.name().to_string();
        let execute_state = self.execute_states[&task_id].clone();
        let task_out_degree = self.rely_graph.get_node_out_degree(&task_id);
        let wait_for_input: Vec<Arc<ExecState>> = task
            .precursors()
            .iter()
            .map(|id| self.execute_states[id].clone())
            .collect();
        let action = task.action();
        let can_continue = self.can_continue.clone();

        tokio::spawn(async move {
            // Wait for the execution result of the predecessor task
            let mut inputs = Vec::with_capacity(wait_for_input.len());
            for wait_for in wait_for_input {
                wait_for.semaphore().acquire().await.unwrap().forget();
                // When the task execution result of the predecessor can be obtained, judge whether
                // the continuation flag is set to false, if it is set to false, cancel the specific
                // execution logic of the task and return immediately.
                if !can_continue.load(Ordering::Acquire) || !wait_for.success() {
                    return Ok(());
                }
                if let Some(content) = wait_for.get_output() {
                    inputs.push(content);
                }
            }
            debug!("Executing task [name: {}, id: {}]", task_name, task_id);
            // Concrete logical behavior for performing tasks.
            panic::catch_unwind(AssertUnwindSafe(|| action.run(Input::new(inputs), env)))
                .map_or_else(
                    |_| {
                        error!("Execution failed [name: {}, id: {}]", task_name, task_id);
                        // TODO: Change this error
                        Err(DagError::EmptyJob)
                    },
                    |out| {
                        // Store execution results
                        if out.is_err() {
                            let error = out.get_err().unwrap_or("".to_string());
                            error!(
                                "Execution failed [name: {}, id: {}] - {}",
                                task_name, task_id, error
                            );
                            execute_state.set_output(out);
                            Err(DagError::TaskError(error))
                        } else {
                            execute_state.set_output(out);
                            execute_state.exe_success();
                            execute_state.semaphore().add_permits(task_out_degree);
                            debug!("Execution succeed [name: {}, id: {}]", task_name, task_id);
                            Ok(())
                        }
                    },
                )
        })
    }

    /// error handling.
    /// When a task execution error occurs, the error handling logic is:
    /// First, set the continuation status to false, and then release the semaphore of the
    /// error task and the tasks after the error task, so that subsequent tasks can quickly
    /// know that some tasks have errors and cannot continue to execute.
    /// After that, the follow-up task finds that the flag that can continue to execute is set
    /// to false, and the specific behavior of executing the task will be cancelled.
    fn handle_error(&self, error_task_id: usize) {
        if self.keep_going {
            self.handle_errored_keep_going(error_task_id);
        } else {
            self.handle_errored_stopping(error_task_id);
        }
    }

    /// When the keep_going flag is set to false, the error handling logic is:
    /// - Set the continuation status to false
    /// - Adding permits for all the subsequent tasks
    fn handle_errored_stopping(&self, error_task_id: usize) {
        if self
            .can_continue
            .compare_exchange(true, false, Ordering::SeqCst, Ordering::Relaxed)
            .is_err()
        {
            return;
        }

        // Find the position of the faulty task in the execution sequence.
        let index = self
            .exe_sequence
            .iter()
            .position(|tid| *tid == error_task_id)
            .unwrap();

        // Add permits for all the subsequent tasks
        for tid in self.exe_sequence.iter().skip(index) {
            self.handle_errored_successor(tid, false);
        }
    }

    /// When the keep_going flag is set to true, the error handling logic is:
    /// - Set the keep_going_errored flag to true
    /// - Adding permits for all tasks that rely on the error task
    /// - Setting them as failed
    fn handle_errored_keep_going(&self, error_task_id: usize) {
        self.keep_going_errored.store(true, Ordering::SeqCst);

        // Add permits for the tasks that rely on the error task
        for successor in self
            .rely_graph
            .get_node_successors(&error_task_id)
            .into_iter()
        {
            let tid = self.rely_graph.find_id_by_index(successor).unwrap();
            self.handle_errored_successor(&tid, true);
        }
    }

    /// Add permits for a task and mark the task as failed if necessary.
    fn handle_errored_successor(&self, tid: &usize, exe_fail: bool) {
        let out_degree = self.rely_graph.get_node_out_degree(tid);
        let exec_state = &self.execute_states[tid];

        exec_state.semaphore().add_permits(out_degree);

        if exe_fail {
            exec_state.exe_fail();
        }
    }

    /// Get the final execution result.
    pub fn get_result<T: Send + Sync + 'static>(&self) -> Option<Arc<T>> {
        if self.exe_sequence.is_empty() {
            None
        } else {
            let last_id = self.exe_sequence.last().unwrap();
            if let Some(content) = self.execute_states[last_id].get_output() {
                content.into_inner()
            } else {
                None
            }
        }
    }

    /// Get the output of all tasks.
    pub fn get_results<T: Send + Sync + 'static>(&self) -> HashMap<usize, Option<Arc<T>>> {
        self
            .execute_states
            .iter()
            .map(|(&id, state)| {
                let output = match state.get_output() {
                    Some(content) => content.into_inner(),
                    None => None,
                };
                (id, output)
            })
            .collect()
    }
    pub fn get_outputs(&self) -> HashMap<usize, Output> {
        self
            .execute_states
            .iter()
            .map(|(&id, state)| {
                let t = state.get_full_output();
                (id, t)
            })
            .collect()
    }

    /// Before the dag starts executing, set the dag's global environment variable.
    pub fn set_env(&mut self, env: EnvVar) {
        self.env = Arc::new(env);
    }
}
