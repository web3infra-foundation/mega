# the directory where the data files is located, such as logs, database, etc.
# can be overridden by environment variable `MEGA_BASE_DIR`
base_dir = "/tmp/.mega"

# Filling the following environment variables with values you set
## Logging Configuration
[log]
# The path which log file is saved
log_path = "${base_dir}/logs"

# log level
level = "debug"

# print std log in console, disable it on production for performance
print_std = true


[database]
# "sqlite" | "postgres"
# "sqlite" will use `db_path` and ignore `db_url`
db_type = "sqlite"

# used for sqlite
db_path = "${base_dir}/mega.db"

# database connection url
db_url = ""

# Maximum number of database connections in the pool.
# A good rule of thumb is to set this to ~2 × CPU cores.
max_connection = 16

# Minimum number of database connections maintained in the pool.
# Typically set to ~1 × CPU cores to ensure baseline concurrency.
min_connection = 8

# Timeout (in seconds) for acquiring a connection from the pool.
# If exceeded, the request will fail.
acquire_timeout = 3

# Timeout (in seconds) for establishing a new database connection.
# If exceeded, the connection attempt will fail.
connect_timeout = 3

# Whether to disabling SQLx Log
sqlx_logging = false

[authentication]
# Support http authentication, login in with github and generate token before push
enable_http_auth = false

# Enable a test user for debugging and development purposes.
# If set to true, the service allows using a predefined test user for authentication.
enable_test_user = true

# Specify the name of the test user.
# This is only relevant if `enable_test_user` is set to true.
test_user_name = "mega"

# Specify the token for the test user.
# This is used for authentication when `enable_test_user` is set to true.
test_user_token = "mega"

[monorepo]
## Only import directory support multi-branch commit and tag, monorepo only support main branch
## Mega treats files under this directory as import repo and other directories as monorepo
import_dir = "/third-party"

# Set System Admin in directory init, replace the admin's github username here
admin = "admin"

# Set serveral root dirs in directory init
root_dirs = ["third-party", "project", "doc", "release"]

[build]

# enable build system trigger
enable_build = false

# build system url
orion_server = "https://orion.gitmega.com"

[pack]
# The maximum memory used by decode
# Support the following units/notations: K, M, G, T, KB, MB, GB, TB, KiB, MiB, GiB, TiB, `%` and decimal percentages
# Capacity units are case-insensitive and can also be spelled as mb or Mb
# Abbreviated units are treated as binary byte units, for example M is treated as MiB
pack_decode_mem_size = "4G"
pack_decode_disk_size = "20%"

# The location where the object stored when the memory used by decode exceeds the limit
pack_decode_cache_path = "${base_dir}/cache"

clean_cache_after_decode = true

# The maximum message size in channel buffer while decode
channel_message_size = 1_000_000

[lfs]
# lfs file storage type, support values can be "local_fs" or "aws_s3"
storage_type = "local_fs"

[lfs.ssh]
# The lfs ssh transport protocol still relies on http to send files
http_url = "http://localhost:8000"

[lfs.local]
# set the local path of the lfs storage
lfs_file_path = "${base_dir}/lfs"

## IMPORTANT: The 'enable_split' feature can only be enabled for new databases. Existing databases do not support this feature.
# Enable or disable splitting large files into smaller chunks
enable_split = true # Default is disabled. Set to true to enable file splitting.

# Size of each file chunk when splitting is enabled. Ignored if splitting is disabled.
split_size = "20M"

[lfs.aws]
s3_bucket = "gitmono"
s3_region = "ap-southeast-2"
s3_access_key_id = ""
s3_secret_access_key = ""
